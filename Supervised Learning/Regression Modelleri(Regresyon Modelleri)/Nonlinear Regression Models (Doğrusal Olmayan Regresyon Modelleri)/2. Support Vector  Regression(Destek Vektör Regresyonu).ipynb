{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression(SVR) - Destek Vektör Regresyonu\n",
    "\n",
    "- Güçlü ve esnek modelleme tekniklerinden birisidir.\n",
    "- Sınıflandırma ve regresyon için kullanılır.\n",
    "- Robust(dayanıklı) bir regresyon modelleme tekniğidir.\n",
    "- **AMAÇ**, Bir marjin aralığına max noktayı en küçük hata ile alabilecek şekilde doğru ya da eğriyi belirlemektir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gerekli Kütüphaneler** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn import  neighbors\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uyarı Mesajları ile Karşılaşmamak için bu kütüphaneyi kullanıyoruz.\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR - Model ve Tahmin İşlemleri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Hitters.csv\")\n",
    "# bu csv dosyasının içerisinde eksik gözlemleri(NA) çıkardık.\n",
    "df = df.dropna()\n",
    "\n",
    "# Veri seti içerisindeki kategorik değişkenleri dummy değişkenlere çeviriyoruz.\n",
    "dms = pd.get_dummies(df[[\"League\",\"Division\",\"NewLeague\"]])\n",
    "\n",
    "# bağımlı değişken\n",
    "y = df[[\"Salary\"]]\n",
    "\n",
    "# Veri Setinin içerisinden Bağımlı Değişkeni ve Kategorik değişkenlerin ilk hallerini dışarı bırakıyoruz.\n",
    "X_ = df.drop([\"Salary\",\"League\",\"Division\",\"NewLeague\"], axis = 1).astype(\"float64\")\n",
    "\n",
    "# dms ile X_ birleştirip(concat) bağımsız değişken oluşturduk.\n",
    "X = pd.concat([X_, dms[[\"League_N\",\"Division_W\",\"NewLeague_N\"]]], axis=1)\n",
    "\n",
    "# train ve test setlerimizi oluşturuyoruz.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state= 42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>328.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>514.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4739.0</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>583.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>593.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2765.0</td>\n",
       "      <td>686.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>233.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>341.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "183  328.0   91.0   12.0  51.0  43.0   33.0    2.0   342.0    94.0    12.0   \n",
       "229  514.0  144.0    0.0  67.0  54.0   79.0    9.0  4739.0  1169.0    13.0   \n",
       "286  593.0  152.0   23.0  69.0  75.0   53.0    6.0  2765.0   686.0   133.0   \n",
       "102  233.0   49.0    2.0  41.0  23.0   18.0    8.0  1350.0   336.0     7.0   \n",
       "153  341.0   95.0    6.0  48.0  42.0   20.0   10.0  2964.0   808.0    81.0   \n",
       "\n",
       "     CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "183   51.0   44.0    33.0    145.0     59.0     8.0         1           0   \n",
       "229  583.0  374.0   528.0    229.0    453.0    15.0         1           0   \n",
       "286  369.0  384.0   321.0    315.0     10.0     6.0         0           1   \n",
       "102  166.0  122.0   106.0    102.0    132.0    10.0         0           0   \n",
       "153  379.0  428.0   221.0    158.0      4.0     5.0         1           1   \n",
       "\n",
       "     NewLeague_N  \n",
       "183            1  \n",
       "229            1  \n",
       "286            0  \n",
       "102            0  \n",
       "153            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(\"linear\").fit(X_train,y_train)\n",
    "# rbf = Doğrusal olmayan radial basis function dır \n",
    "svr_model_rbf = SVR(\"rbf\").fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        SVR\n",
       "\u001b[1;31mString form:\u001b[0m SVR(kernel='linear')\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\halil\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Epsilon-Support Vector Regression.\n",
       "\n",
       "The free parameters in the model are C and epsilon.\n",
       "\n",
       "The implementation is based on libsvm. The fit time complexity\n",
       "is more than quadratic with the number of samples which makes it hard\n",
       "to scale to datasets with more than a couple of 10000 samples. For large\n",
       "datasets consider using :class:`sklearn.svm.LinearSVR` or\n",
       ":class:`sklearn.linear_model.SGDRegressor` instead, possibly after a\n",
       ":class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
       "\n",
       "Read more in the :ref:`User Guide <svm_regression>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
       "     Specifies the kernel type to be used in the algorithm.\n",
       "     It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
       "     a callable.\n",
       "     If none is given, 'rbf' will be used. If a callable is given it is\n",
       "     used to precompute the kernel matrix.\n",
       "\n",
       "degree : int, default=3\n",
       "    Degree of the polynomial kernel function ('poly').\n",
       "    Ignored by all other kernels.\n",
       "\n",
       "gamma : {'scale', 'auto'} or float, default='scale'\n",
       "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
       "\n",
       "    - if ``gamma='scale'`` (default) is passed then it uses\n",
       "      1 / (n_features * X.var()) as value of gamma,\n",
       "    - if 'auto', uses 1 / n_features.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "       The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
       "\n",
       "coef0 : float, default=0.0\n",
       "    Independent term in kernel function.\n",
       "    It is only significant in 'poly' and 'sigmoid'.\n",
       "\n",
       "tol : float, default=1e-3\n",
       "    Tolerance for stopping criterion.\n",
       "\n",
       "C : float, default=1.0\n",
       "    Regularization parameter. The strength of the regularization is\n",
       "    inversely proportional to C. Must be strictly positive.\n",
       "    The penalty is a squared l2 penalty.\n",
       "\n",
       "epsilon : float, default=0.1\n",
       "     Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
       "     within which no penalty is associated in the training loss function\n",
       "     with points predicted within a distance epsilon from the actual\n",
       "     value.\n",
       "\n",
       "shrinking : bool, default=True\n",
       "    Whether to use the shrinking heuristic.\n",
       "    See the :ref:`User Guide <shrinking_svm>`.\n",
       "\n",
       "cache_size : float, default=200\n",
       "    Specify the size of the kernel cache (in MB).\n",
       "\n",
       "verbose : bool, default=False\n",
       "    Enable verbose output. Note that this setting takes advantage of a\n",
       "    per-process runtime setting in libsvm that, if enabled, may not work\n",
       "    properly in a multithreaded context.\n",
       "\n",
       "max_iter : int, default=-1\n",
       "    Hard limit on iterations within solver, or -1 for no limit.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "support_ : ndarray of shape (n_SV,)\n",
       "    Indices of support vectors.\n",
       "\n",
       "support_vectors_ : ndarray of shape (n_SV, n_features)\n",
       "    Support vectors.\n",
       "\n",
       "dual_coef_ : ndarray of shape (1, n_SV)\n",
       "    Coefficients of the support vector in the decision function.\n",
       "\n",
       "coef_ : ndarray of shape (1, n_features)\n",
       "    Weights assigned to the features (coefficients in the primal\n",
       "    problem). This is only available in the case of a linear kernel.\n",
       "\n",
       "    `coef_` is readonly property derived from `dual_coef_` and\n",
       "    `support_vectors_`.\n",
       "\n",
       "fit_status_ : int\n",
       "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
       "\n",
       "intercept_ : ndarray of shape (1,)\n",
       "    Constants in decision function.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.svm import SVR\n",
       ">>> from sklearn.pipeline import make_pipeline\n",
       ">>> from sklearn.preprocessing import StandardScaler\n",
       ">>> import numpy as np\n",
       ">>> n_samples, n_features = 10, 5\n",
       ">>> rng = np.random.RandomState(0)\n",
       ">>> y = rng.randn(n_samples)\n",
       ">>> X = rng.randn(n_samples, n_features)\n",
       ">>> regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
       ">>> regr.fit(X, y)\n",
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svr', SVR(epsilon=0.2))])\n",
       "\n",
       "\n",
       "See also\n",
       "--------\n",
       "NuSVR\n",
       "    Support Vector Machine for regression implemented using libsvm\n",
       "    using a parameter to control the number of support vectors.\n",
       "\n",
       "LinearSVR\n",
       "    Scalable Linear Support Vector Machine for regression\n",
       "    implemented using liblinear.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "**References:**\n",
       "`LIBSVM: A Library for Support Vector Machines\n",
       "<http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`__\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_n_features',\n",
       " '_compute_kernel',\n",
       " '_decision_function',\n",
       " '_dense_decision_function',\n",
       " '_dense_fit',\n",
       " '_dense_predict',\n",
       " '_dual_coef_',\n",
       " '_estimator_type',\n",
       " '_gamma',\n",
       " '_get_coef',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_impl',\n",
       " '_intercept_',\n",
       " '_more_tags',\n",
       " '_n_support',\n",
       " '_pairwise',\n",
       " '_probA',\n",
       " '_probB',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_sparse',\n",
       " '_sparse_decision_function',\n",
       " '_sparse_fit',\n",
       " '_sparse_kernels',\n",
       " '_sparse_predict',\n",
       " '_validate_data',\n",
       " '_validate_for_predict',\n",
       " '_validate_targets',\n",
       " '_warn_from_fit_status',\n",
       " 'cache_size',\n",
       " 'class_weight',\n",
       " 'class_weight_',\n",
       " 'coef0',\n",
       " 'coef_',\n",
       " 'degree',\n",
       " 'dual_coef_',\n",
       " 'epsilon',\n",
       " 'fit',\n",
       " 'fit_status_',\n",
       " 'gamma',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'kernel',\n",
       " 'max_iter',\n",
       " 'n_features_in_',\n",
       " 'n_support_',\n",
       " 'nu',\n",
       " 'predict',\n",
       " 'probA_',\n",
       " 'probB_',\n",
       " 'probability',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'shape_fit_',\n",
       " 'shrinking',\n",
       " 'support_',\n",
       " 'support_vectors_',\n",
       " 'tol',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(svr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tahmin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219.32622169, 702.4303869 , 623.2055964 , 153.77538476,\n",
       "       463.15190834])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.predict(X_train)[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([404.04653122, 475.7979806 , 447.47083279, 416.62375328,\n",
       "       451.10639712])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model_rbf.predict(X_train)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([679.14754685, 633.72883069, 925.68640849, 270.28463621,\n",
       "       530.26659184])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.predict(X_test)[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([467.17641555, 446.40313543, 478.61634896, 407.90736132,\n",
       "       478.21333994])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model_rbf.predict(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-80.15196151])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.21839037,   6.09602969,  -3.67574533,   0.14217075,\n",
       "          0.51435919,   1.28388986,  12.55922537,  -0.08693755,\n",
       "          0.46597184,   2.98259944,   0.52944523,  -0.79820799,\n",
       "         -0.16015534,   0.30872794,   0.28842348,  -1.79560067,\n",
       "          6.41868985, -10.74313783,   1.33374317]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370.04084185624924"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ilkel test hatası, manuel olarak = el yordamıyla oluşturduğumuz test hatası\n",
    "#linear\n",
    "y_pred = svr_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460.0032657244849"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf ye göre ilkel test hatası, linear a göre negatif yönlü test hatası oluştu çünkü değeri 370 den 460 oldu. \n",
    "y_pred = svr_model_rbf.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR(\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        SVR\n",
       "\u001b[1;31mString form:\u001b[0m SVR(kernel='linear')\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\halil\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_classes.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Epsilon-Support Vector Regression.\n",
       "\n",
       "The free parameters in the model are C and epsilon.\n",
       "\n",
       "The implementation is based on libsvm. The fit time complexity\n",
       "is more than quadratic with the number of samples which makes it hard\n",
       "to scale to datasets with more than a couple of 10000 samples. For large\n",
       "datasets consider using :class:`sklearn.svm.LinearSVR` or\n",
       ":class:`sklearn.linear_model.SGDRegressor` instead, possibly after a\n",
       ":class:`sklearn.kernel_approximation.Nystroem` transformer.\n",
       "\n",
       "Read more in the :ref:`User Guide <svm_regression>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}, default='rbf'\n",
       "     Specifies the kernel type to be used in the algorithm.\n",
       "     It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
       "     a callable.\n",
       "     If none is given, 'rbf' will be used. If a callable is given it is\n",
       "     used to precompute the kernel matrix.\n",
       "\n",
       "degree : int, default=3\n",
       "    Degree of the polynomial kernel function ('poly').\n",
       "    Ignored by all other kernels.\n",
       "\n",
       "gamma : {'scale', 'auto'} or float, default='scale'\n",
       "    Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
       "\n",
       "    - if ``gamma='scale'`` (default) is passed then it uses\n",
       "      1 / (n_features * X.var()) as value of gamma,\n",
       "    - if 'auto', uses 1 / n_features.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "       The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
       "\n",
       "coef0 : float, default=0.0\n",
       "    Independent term in kernel function.\n",
       "    It is only significant in 'poly' and 'sigmoid'.\n",
       "\n",
       "tol : float, default=1e-3\n",
       "    Tolerance for stopping criterion.\n",
       "\n",
       "C : float, default=1.0\n",
       "    Regularization parameter. The strength of the regularization is\n",
       "    inversely proportional to C. Must be strictly positive.\n",
       "    The penalty is a squared l2 penalty.\n",
       "\n",
       "epsilon : float, default=0.1\n",
       "     Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
       "     within which no penalty is associated in the training loss function\n",
       "     with points predicted within a distance epsilon from the actual\n",
       "     value.\n",
       "\n",
       "shrinking : bool, default=True\n",
       "    Whether to use the shrinking heuristic.\n",
       "    See the :ref:`User Guide <shrinking_svm>`.\n",
       "\n",
       "cache_size : float, default=200\n",
       "    Specify the size of the kernel cache (in MB).\n",
       "\n",
       "verbose : bool, default=False\n",
       "    Enable verbose output. Note that this setting takes advantage of a\n",
       "    per-process runtime setting in libsvm that, if enabled, may not work\n",
       "    properly in a multithreaded context.\n",
       "\n",
       "max_iter : int, default=-1\n",
       "    Hard limit on iterations within solver, or -1 for no limit.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "support_ : ndarray of shape (n_SV,)\n",
       "    Indices of support vectors.\n",
       "\n",
       "support_vectors_ : ndarray of shape (n_SV, n_features)\n",
       "    Support vectors.\n",
       "\n",
       "dual_coef_ : ndarray of shape (1, n_SV)\n",
       "    Coefficients of the support vector in the decision function.\n",
       "\n",
       "coef_ : ndarray of shape (1, n_features)\n",
       "    Weights assigned to the features (coefficients in the primal\n",
       "    problem). This is only available in the case of a linear kernel.\n",
       "\n",
       "    `coef_` is readonly property derived from `dual_coef_` and\n",
       "    `support_vectors_`.\n",
       "\n",
       "fit_status_ : int\n",
       "    0 if correctly fitted, 1 otherwise (will raise warning)\n",
       "\n",
       "intercept_ : ndarray of shape (1,)\n",
       "    Constants in decision function.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.svm import SVR\n",
       ">>> from sklearn.pipeline import make_pipeline\n",
       ">>> from sklearn.preprocessing import StandardScaler\n",
       ">>> import numpy as np\n",
       ">>> n_samples, n_features = 10, 5\n",
       ">>> rng = np.random.RandomState(0)\n",
       ">>> y = rng.randn(n_samples)\n",
       ">>> X = rng.randn(n_samples, n_features)\n",
       ">>> regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
       ">>> regr.fit(X, y)\n",
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('svr', SVR(epsilon=0.2))])\n",
       "\n",
       "\n",
       "See also\n",
       "--------\n",
       "NuSVR\n",
       "    Support Vector Machine for regression implemented using libsvm\n",
       "    using a parameter to control the number of support vectors.\n",
       "\n",
       "LinearSVR\n",
       "    Scalable Linear Support Vector Machine for regression\n",
       "    implemented using liblinear.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "**References:**\n",
       "`LIBSVM: A Library for Support Vector Machines\n",
       "<http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`__\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?svr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = ceza parametresidir.\n",
    "svr_params = {\"C\": [0.1, 0.5,1,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_cv_model = GridSearchCV(svr_model,svr_params,cv = 5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C değerleri içerisinden hangi parametrenin daha iyi olduğunu bulmuş olduk.\n",
    "# Yani C nin 0.5 noktasındaki değerinin en iyi değer oludğunu anlamış olduk.\n",
    "svr_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  20 | elapsed:   16.9s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   34.5s finished\n"
     ]
    }
   ],
   "source": [
    "# verbose = 2 değeri çalışma esnasındaki durumu raporlayarak çalışma gerçekleştirir.\n",
    "# n_jobs = -1 değeri ise işlemcinin max performans ile çalışmasını sağlar.\n",
    "svr_cv_model = GridSearchCV(svr_model,svr_params,cv = 5, verbose = 2, n_jobs= -1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.5}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = svr_cv_model.best_params_ \n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Modeli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_tuned = SVR(\"linear\", C = 0.5 ).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svr_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367.9874739022889"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RSME \n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
